import cv2
import torch
import numpy as np


def vae_experiment(cfgs):
    train_vae_and_update_variant(cfgs)


def train_vae_and_update_variant(variant):
    from rorlkit.core import logger
    train_vae_variant = variant['train_vae_variant']
    logger.remove_tabular_output(
        'progress.csv', relative_to_snapshot_dir=True
    )
    logger.add_tabular_output(
        'vae_progress.csv', relative_to_snapshot_dir=True
    )
    vae, vae_train_data, vae_test_data = train_vae(train_vae_variant, return_data=True)
    logger.save_extra_data(vae, 'vae.pkl', mode='pickle')
    logger.remove_tabular_output(
        'vae_progress.csv',
        relative_to_snapshot_dir=True,
    )
    logger.add_tabular_output(
        'progress.csv',
        relative_to_snapshot_dir=True,
    )


def train_vae(variant, return_data=False):
    from rlkit.util.ml_util import PiecewiseLinearSchedule
    from rorlkit.torch.vae.conv_vae import (
        ConvVAE,
    )
    import rorlkit.torch.vae.conv_vae as conv_vae
    from rorlkit.torch.vae.vae_trainer import ConvVAETrainer
    from rorlkit.core import logger
    import rlkit.torch.pytorch_util as ptu
    from rlkit.pythonplusplus import identity
    import torch

    beta = variant["beta"]
    representation_size = variant["representation_size"]
    train_data, test_data = prepare_vae_dataset(variant)
    # train_data, test_data, info = generate_vae_dataset(cfgs)
    # logger.save_extra_data(info)
    logger.get_snapshot_dir()

    if 'beta_schedule_kwargs' in variant:
        beta_schedule = PiecewiseLinearSchedule(
            **variant['beta_schedule_kwargs'])
    else:
        beta_schedule = None
    if variant.get('decoder_activation', None) == 'sigmoid':
        decoder_activation = torch.nn.Sigmoid()
    else:
        decoder_activation = identity
    architecture = variant['vae_kwargs'].get('architecture', None)
    if not architecture and variant.get('imsize') == 84:
        architecture = conv_vae.imsize84_default_architecture
    elif not architecture and variant.get('imsize') == 48:
        architecture = conv_vae.imsize48_default_architecture
    variant['vae_kwargs']['architecture'] = architecture
    variant['vae_kwargs']['imsize'] = variant.get('imsize')

    m = ConvVAE(
        representation_size,
        decoder_output_activation=decoder_activation,
        **variant['vae_kwargs']
    )
    m.to(ptu.device)
    t = ConvVAETrainer(train_data, test_data, m, beta=beta,
                       beta_schedule=beta_schedule, **variant['algo_kwargs'])
    save_period = variant['save_period']
    for epoch in range(variant['num_epochs']):
        should_save_imgs = (epoch % save_period == 0)
        t.train_epoch(epoch)
        t.test_epoch(
            epoch,
            save_reconstruction=should_save_imgs,
            save_vae=False,
        )
        if should_save_imgs:
            t.dump_samples(epoch)
        t.update_train_weights()
    logger.save_extra_data(m, 'vae.pkl', mode='pickle')
    if return_data:
        return m, train_data, test_data
    return m


def prepare_vae_dataset(variant, flatted_data=False):
    """Pre-process the dataset to RoRL standard input format (b, c*w*h).
    The raw images generated by OpenCV is HWC rgb ndarray with shape (b, h, w, c), but
    the standard format needs the order to be CWH.
    :param variant: dict
    :param flatted_data: if true, the raw_images is generated by mujoco, otherwise by OpenCV
    """
    if variant.get('flatted_data', None) is not None:
        flatted_data = variant.get('flatted_data')
    ratio = variant.get('test_p', 0.9)
    imsize = variant.get('imsize')
    assert imsize is not None
    data_path = variant.get('data_path')
    proc_images = []
    raw_images = np.load(data_path)
    if not flatted_data:
        for image in raw_images:
            image = cv2.resize(image, (imsize, imsize))
            cv2.imshow('samples', image)
            cv2.waitKey(1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            # The images are in HWC order
            proc_images.append(image)
        dataset = np.asarray(proc_images)
        # swap order and reshape
        dataset = torch.from_numpy(dataset).permute(0, 3, 2, 1).flatten(start_dim=1).numpy()
    else:
        dataset = raw_images

    n = int(len(dataset) * ratio)
    train_dataset = dataset[:n, :]
    test_dataset = dataset[n:, :]
    return train_dataset, test_dataset
